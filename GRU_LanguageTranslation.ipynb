{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWrrL6izWenDmuMpLT+QXx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Munna-Prasad-Gupta/DL/blob/main/GRU_LanguageTranslation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRiG5IYPj3eQ",
        "outputId": "f7ced154-638b-41c7-9782-2a1de5989a79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50225, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import collections\n",
        "\n",
        "\n",
        "hf = pd.read_excel('tenthou.xlsx')\n",
        "\n",
        "hf.columns\n",
        "hf.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hindi_sentences = hf['hindi']\n",
        "telugu_sentences = hf['telugu']\n",
        "hindi_sentences.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "PIDDuqaZkPYM",
        "outputId": "9adc52ef-46fb-43f0-f884-6b81ed27e414"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         आभूषणों की निंदा करना हमारा उद्देश्य नहीं है\n",
              "1    हम असहयोग का उत्पीड़न सह सकते हैं पर ललनाओं के ...\n",
              "2    तो भी इतना अवश्य कहेंगे कि इस तृष्णा की पूर्ति...\n",
              "3    यद्यपि हमने किसी रूप हीना महिला को आभूषणों की ...\n",
              "4    किन्तु शारीरिक शोभा के लिए हम तन को कितना मलिन...\n",
              "Name: hindi, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hindi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>आभूषणों की निंदा करना हमारा उद्देश्य नहीं है</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>हम असहयोग का उत्पीड़न सह सकते हैं पर ललनाओं के ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>तो भी इतना अवश्य कहेंगे कि इस तृष्णा की पूर्ति...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>यद्यपि हमने किसी रूप हीना महिला को आभूषणों की ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>किन्तु शारीरिक शोभा के लिए हम तन को कितना मलिन...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hindi_words_counter = collections.Counter(\n",
        "    word for sentence in hindi_sentences if isinstance(sentence, str) for word in sentence.lower().split()\n",
        ")\n",
        "telugu_words_counter = collections.Counter(\n",
        "    word for sentence in telugu_sentences if isinstance(sentence, str) for word in sentence.lower().split()\n",
        ")\n",
        "\n",
        "print('{} hindi words.'.format(len([word for sentence in hindi_sentences if isinstance(sentence,str) for word in sentence.split()])))\n",
        "print('{} unique hindi words.'.format(len(hindi_words_counter)))\n",
        "print('10 Most common words in the Hindi dataset:')\n",
        "print('\"' + '\" \"'.join(list(zip(*hindi_words_counter.most_common(10)))[0]) + '\"')\n",
        "print()\n",
        "print('{} telugu words.'.format(len([word for sentence in telugu_sentences if isinstance(sentence,str) for word in sentence.split()])))\n",
        "print('{} unique telugu words.'.format(len(telugu_words_counter)))\n",
        "print('10 Most common words in the telugu dataset:')\n",
        "print('\"' + '\" \"'.join(list(zip(*telugu_words_counter.most_common(10)))[0])+'\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOwl1vHRkS1O",
        "outputId": "33db240a-cf10-45a1-caa7-07ca247a72be"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "584354 hindi words.\n",
            "25748 unique hindi words.\n",
            "10 Most common words in the Hindi dataset:\n",
            "\"है\" \"में\" \"तो\" \"नहीं\" \"के\" \"से\" \"और\" \"की\" \"का\" \"हो\"\n",
            "\n",
            "388883 telugu words.\n",
            "60400 unique telugu words.\n",
            "10 Most common words in the telugu dataset:\n",
            "\"మరియు\" \"నేను\" \"ఈ\" \"కూడా\" \"మీరు\" \"కానీ\" \"నా\" \"అతను\" \"అతని\" \"చాలా\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "tokenizer_hindi = Tokenizer()\n",
        "tokenizer_telugu=Tokenizer()"
      ],
      "metadata": {
        "id": "43poelMhkY2p"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAqCtOgNkxki",
        "outputId": "a64c41f9-2cd6-4b2f-b5e5-16e9f48d3ed2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 847570824963107596\n",
            "xla_global_id: -1\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def word_tokenize(sentences):\n",
        "    words = []\n",
        "    for s in sentences:\n",
        "        if isinstance(s, str):  # Check if the entry is a string\n",
        "            words.append(s.split())\n",
        "        else:\n",
        "            words.append([])  # Append an empty list or handle as needed\n",
        "    return words\n",
        "\n",
        "# Now call the function\n",
        "tokenized_hindi_words = word_tokenize(hindi_sentences)\n",
        "tokenized_telugu_words = word_tokenize(telugu_sentences)"
      ],
      "metadata": {
        "id": "3osX8vnKk3Zr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_hindi.fit_on_texts(tokenized_hindi_words)\n",
        "\n",
        "len(tokenizer_hindi.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGLEgq5lk-U3",
        "outputId": "d49ceb8e-fba1-4b17-fcab-e29ce32622b3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25748"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_telugu.fit_on_texts(tokenized_telugu_words)\n",
        "\n",
        "len(tokenizer_telugu.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2A-ijW8lEkB",
        "outputId": "c8501940-73de-404c-927c-7d1806a9abb2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60400"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_to_vector(sentences,tokenizer):\n",
        "  input = []\n",
        "  for s in sentences:\n",
        "    if isinstance(s, str):  # Check if the entry is a string\n",
        "      input.append(tokenizer.texts_to_sequences([s])[0])\n",
        "  return input\n",
        "\n",
        "\n",
        "hindi_sentence_vectors = sentence_to_vector(hindi_sentences,tokenizer_hindi)\n",
        "telugu_sentence_vectors = sentence_to_vector(telugu_sentences,tokenizer_telugu)\n",
        "\n",
        "len(hindi_sentence_vectors)\n",
        "len(telugu_sentence_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BseR6q3xlIz8",
        "outputId": "7009d53f-3938-46b3-bd71-7f5b7b4ba531"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50216"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hindi_sentence_vectors[0]\n",
        "telugu_sentence_vectors[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deNqaCyYlOMQ",
        "outputId": "5dd15ea7-fec8-4474-ac3f-c0eb40a3da5f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4482, 7049, 79, 2095, 70]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxlength_hindi_sent =max([len(x) for x in hindi_sentence_vectors])\n",
        "maxlength_telugu_sent =max([len(x) for x in telugu_sentence_vectors])\n",
        "\n",
        "print(f\"max length of hindi sentence is {maxlength_hindi_sent}\")\n",
        "print(f\"max length of telugu sentence is {maxlength_telugu_sent}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRRZyhhJlSBy",
        "outputId": "6feeefa1-9346-4ad9-ce3d-0a733df5f3ed"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max length of hindi sentence is 87\n",
            "max length of telugu sentence is 59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# max length of hindi sentence is 85\n",
        "# max length of telugu sentence is 57\n",
        "\n",
        "padded_hindi_sentences = pad_sequences(hindi_sentence_vectors,maxlen=maxlength_hindi_sent,padding='post')\n",
        "padded_telugu_sentences = pad_sequences(telugu_sentence_vectors,maxlen=maxlength_telugu_sent,padding='post')\n",
        "\n",
        "X=padded_hindi_sentences\n",
        "y=padded_telugu_sentences\n",
        "\n",
        "len(padded_hindi_sentences)\n",
        "len(padded_telugu_sentences)\n",
        "\n",
        "hindi_vocab_size = len(hindi_words_counter) + 1\n",
        "telugu_vocab_size= len(telugu_words_counter) +1\n",
        "\n",
        "print(f\"hindi vocab size is {hindi_vocab_size}\")\n",
        "print(f\"telugu vocab size is {telugu_vocab_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50uzlhAIlUb9",
        "outputId": "b2cbcdc6-0b27-48a2-d8b6-5fea33943264"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hindi vocab size is 25749\n",
            "telugu vocab size is 60401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, TimeDistributed, Dense, Dropout, Embedding, RepeatVector\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "\n",
        "# Model parameters\n",
        "embedding_size = 256  # Size of the embedding vector\n",
        "units = 512  # Number of GRU units\n",
        "learning_rate = 0.005\n",
        "\n",
        "def build_gru_model(input_length, output_length, hindi_vocab_size, telugu_vocab_size):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Embedding layer for Hindi sentences\n",
        "    model.add(Embedding(hindi_vocab_size, embedding_size, input_length=input_length))\n",
        "\n",
        "    # GRU layer that outputs a fixed-length vector\n",
        "    model.add(GRU(units))\n",
        "\n",
        "    # Repeat the output vector to match the length of the target sequence (Telugu sentence length)\n",
        "    model.add(RepeatVector(output_length))\n",
        "\n",
        "    # GRU layer with return_sequences=True to match the Telugu sentence length (57)\n",
        "    model.add(GRU(units, return_sequences=True))\n",
        "\n",
        "    # Time-distributed dense layer to output the same length as the target (Telugu)\n",
        "    model.add(TimeDistributed(Dense(1024, activation='relu')))\n",
        "\n",
        "    # Dropout layer for regularization\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # Output layer with softmax activation for predicting the Telugu vocabulary words\n",
        "    model.add(TimeDistributed(Dense(telugu_vocab_size, activation='softmax')))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(learning_rate),\n",
        "                  loss=sparse_categorical_crossentropy,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create the model with Hindi input length (85) and Telugu output length (57)\n",
        "model = build_gru_model(input_length=85, output_length=59, hindi_vocab_size=hindi_vocab_size, telugu_vocab_size=telugu_vocab_size)\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "# Now train the model\n",
        "model.fit(X, y, batch_size=64, epochs=20, validation_split=0.2)\n",
        "\n",
        "\n",
        "\n",
        "# Save the trained model\n",
        "model.save('hindi_to_telugu_gru_model.h5')\n",
        "print(\"Model saved as 'hindi_to_telugu_gru_model.h5'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "MM5HI4dtlXSK",
        "outputId": "b2393127-4490-49eb-dcae-dd878ddb0571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_8 (\u001b[38;5;33mGRU\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ repeat_vector_4 (\u001b[38;5;33mRepeatVector\u001b[0m)       │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_9 (\u001b[38;5;33mGRU\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_8 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_9 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ repeat_vector_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)       │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m  2/628\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:47:46\u001b[0m 56s/step - accuracy: 0.2176 - loss: 10.8454 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model('hindi_to_telugu_gru_model.h5')\n",
        "print(\"Model loaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "kD8UKO0gllOJ",
        "outputId": "e39be33f-8595-4115-8c77-4abec92261a7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'hindi_to_telugu_gru_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-54ce8b5989bc>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the saved model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hindi_to_telugu_gru_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model loaded successfully.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    187\u001b[0m         )\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         return legacy_h5_format.load_model_from_hdf5(\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    560\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 562\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'hindi_to_telugu_gru_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_hindi_to_telugu(model, hindi_sentence, hindi_tokenizer, telugu_tokenizer, input_length=85):\n",
        "    \"\"\"\n",
        "    Translate a given Hindi sentence to Telugu using the trained GRU model.\n",
        "\n",
        "    :param model: Trained GRU model\n",
        "    :param hindi_sentence: The Hindi sentence to translate (string)\n",
        "    :param hindi_tokenizer: Tokenizer used for Hindi language\n",
        "    :param telugu_tokenizer: Tokenizer used for Telugu language\n",
        "    :param input_length: Max length of the Hindi sentence (default is 85)\n",
        "    :return: Translated Telugu sentence (string)\n",
        "    \"\"\"\n",
        "    # Tokenize and pad the Hindi sentence\n",
        "    hindi_sequence = hindi_tokenizer.texts_to_sequences([hindi_sentence])\n",
        "    hindi_padded = pad_sequences(hindi_sequence, maxlen=input_length, padding='post')\n",
        "\n",
        "    # Get the model's prediction\n",
        "    predicted_logits = model.predict(hindi_padded)\n",
        "\n",
        "    # Convert logits to Telugu sentence\n",
        "    translated_sentence = logits_to_text(predicted_logits[0], telugu_tokenizer)\n",
        "\n",
        "    return translated_sentence\n",
        "\n",
        "def logits_to_text(logits, tokenizer):\n",
        "    \"\"\"\n",
        "    Convert predicted logits to a human-readable sentence using the tokenizer.\n",
        "\n",
        "    :param logits: The predicted output from the model (logits)\n",
        "    :param tokenizer: The tokenizer for the target language (Telugu)\n",
        "    :return: Decoded sentence (string)\n",
        "    \"\"\"\n",
        "    index_to_word = {id: word for word, id in tokenizer.word_index.items()}\n",
        "    decoded_sentence = ' '.join([index_to_word.get(np.argmax(logit), '') for logit in logits if np.argmax(logit) > 0])\n",
        "    return decoded_sentence.strip()\n",
        "\n",
        "# Example usage:\n",
        "# Assuming the model has been trained and hindi_tokenizer and telugu_tokenizer are available\n",
        "hindi_sentence = \"आपका नाम क्या है?\"  # Example Hindi sentence\n",
        "translated_sentence = translate_hindi_to_telugu(model, hindi_sentence, hindi_tokenizer, telugu_tokenizer)\n",
        "\n",
        "print(\"Translated Telugu sentence:\", translated_sentence)\n"
      ],
      "metadata": {
        "id": "4jyrdshol1mv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}